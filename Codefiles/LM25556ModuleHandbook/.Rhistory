packages <- c("dplyr", "ggplot2","tidyverse", "moderndive",
"ggfortify", "performance", "car", "skimr", "gridExtra", "broom",
"ggeffects","MASS","MuMIn")
# Load all packages and install the packages we have no previously installed on the system
lapply(packages, library, character.only = TRUE)
setwd("~/Documents/GitHub/Teaching/LM_25556Environmental_Analysis/Codefiles/LM25556ModuleHandbook")
# Load data
gotelli <- read_csv("~/Documents/GitHub/Teaching/LM_25556Environmental_Analysis/Data/gotelli.csv")
glimpse(gotelli)
skim(gotelli)
scatterplotMatrix(~Srich
+ Latitude + Elevation,
diag = list(method = "qqplot"),
regLine = list(col = "blue", lwd = 2),   # Linear regression line in blue
smooth = list(col.smooth = "blue", lty.smooth = 2, lwd.smooth = 2), # Loess in blue, dashed
data = gotelli)
# boxplot
ggplot(gotelli, aes(x=as.factor(Habitat), y=Srich)) +
geom_boxplot() +
theme_bw() +
theme(
panel.grid.minor = element_blank(), #remove the minor grids
panel.grid.major = element_blank(), #remove the minor grids
)
gotelli.glm <- glm(Srich ~ as.factor(Habitat) + Latitude + Elevation,
family = poisson, data  = gotelli)
gvif_values <- performance::check_collinearity(gotelli.glm)
print(gvif_values)
gotelli <- gotelli %>%
mutate(
cLatitude  = as.numeric(scale(Latitude,  center = TRUE, scale = TRUE)),
cElevation = as.numeric(scale(Elevation, center = TRUE, scale = TRUE))
)
gotelli.glm <- glm(Srich ~ as.factor(Habitat) * cLatitude * cElevation,
family = poisson, data  = gotelli)
summary(gotelli.glm)
null_deviance <- gotelli.glm$null.deviance #
residual_deviance <- gotelli.glm$deviance
proportion_explained <- (null_deviance - residual_deviance) / null_deviance
# Print result
cat("Proportion of Deviance Explained:", proportion_explained, "\n")
check_overdispersion(gotelli.glm)
dispersion_stat <- sum(residuals(gotelli.glm, type = "pearson")^2) / gotelli.glm$df.residual
cat("Dispersion Statistic:", dispersion_stat, "\n")
options(na.action=na.fail) # set options in Base R concerning missing values
summary(model.avg(dredge(gotelli.glm), fit = TRUE, subset = TRUE))
options(na.action = "na.omit") # reset base R options
gotelli.glm <- glm(Srich ~ as.factor(Habitat) + cLatitude + cElevation,
family=poisson, data = gotelli)
summary(gotelli.glm)
## simulate residuals
autoplot(gotelli.glm, method="glm")
## plot simulated residuals
plot(gotelli.glm, which=4)
pres <- residuals.glm(gotelli.glm, type="pearson") # strip the residuals
#plot against the predictor variables in a panel plot
par(mfrow = c(2, 2))  # Set 3 rows and 2 columns
plot(pres ~ gotelli$cLatitude)
plot(pres ~ gotelli$cElevation)
boxplot(pres ~ as.factor(gotelli$Habitat))
par(mfrow = c(1, 1))
tidy(gotelli.glm, exponentiate = TRUE)
# Ensure your categorical variable is a factor
gotelli$Habitat <- as.factor(gotelli$Habitat)
# Calculate the mean and sd directly from the RAW data columns in our gotelli dataframe
lat_center <- mean(gotelli$Latitude, na.rm = TRUE)
lat_scale  <- sd(gotelli$Latitude, na.rm = TRUE)
elev_mean  <- mean(gotelli$Elevation, na.rm = TRUE)
elev_center <- mean(gotelli$Elevation, na.rm = TRUE)
elev_scale  <- sd(gotelli$Elevation, na.rm = TRUE)
# Create a grid of predictor values for the plot
prediction_grid <- expand.grid(
Latitude = seq(42, 45, length.out = 100),
Habitat = levels(gotelli$Habitat), # it is essential the variable is a factor not a character class
Elevation = elev_mean
)
# Transform the grid to match the model's predictors
prediction_grid_transformed <- prediction_grid |>
mutate(
cLatitude = (Latitude - lat_center) / lat_scale,
cElevation = (Elevation - elev_center) / elev_scale
)
# Generate predictions
predictions <- predict(gotelli.glm,
newdata = prediction_grid_transformed,
type = "response", # this command exponentiates the logged values back to their measured state.
se.fit = TRUE)
# Combine everything into a final, clean prediction data frame
predictions_df <- cbind(prediction_grid,
predicted_Srich = predictions$fit,
se = predictions$se.fit) |>
mutate(
lwr = predicted_Srich - 1.96 * se,
upr = predicted_Srich + 1.96 * se
)
# Create the plot
# Notice that the first layer now uses our initial 'gotelli' data frame.
ggplot() +
# Layer 1: The raw data points from the 'gotelli' data frame
geom_point(data = gotelli, aes(x = Latitude, y = Srich, shape = Habitat), size = 2.5) +
# Layer 2 & 3: The predictions (from the new 'predictions_df')
geom_ribbon(data = predictions_df,
aes(x = Latitude, ymin = lwr, ymax = upr, fill = Habitat),
alpha = 0.2) +
geom_line(data = predictions_df,
aes(x = Latitude, y = predicted_Srich, color = Habitat),
linewidth = 1) +
# code for scales, labse)
scale_color_manual(values = c("Forest" = "black", "Bog" = "black")) +
scale_fill_manual(values = c("Forest" = "gray50", "Bog" = "gray50")) +
scale_shape_manual(values = c("Forest" = 16, "Bog" = 21)) +
labs(
title = "A Comparison of Global Ant Species Richness in Forest / Bog Habitats and Latitude",
x = "Latitude",
y = "Ant Species Richness"
) +
theme_bw() +
theme(
legend.position = "top",
legend.justification = "right",
legend.box.background = element_rect(color = "white")
)
road <- read_csv("~/Documents/GitHub/Teaching/LM_25556Environmental_Analysis/Data/RoadKills.csv")
glimpse(road)
checks <- skim(road) # create tibble (a form dataframe created by dplyr)
checks
# Select only the columns you want to plot
# We need TOT.N (our response) plus all the desired X-variables (possible explanatories)
eda <- road %>%
dplyr::select(
TOT.N, BufoCalamita, S.RICH, OPEN.L, OLIVE, MONT.S, MONT,
POLIC, SHRUB, URBAN, WAT.RES, L.WAT.C, L.D.ROAD, L.P.ROAD,
D.WAT.RES, D.WAT.COUR, D.PARK, N.PATCH, P.EDGE, L.SDI
) %>%
pivot_longer(
cols = -c(TOT.N, BufoCalamita, S.RICH),             # Pivot all columns EXCEPT TOT.N,BufoCalamita,S.RICH
names_to = "variables",    # New column for the name of the X-predictor
values_to = "value"       # New column for the value of the X-predictor
)
ggplot(eda, aes(sample = value)) +
stat_qq() +
stat_qq_line(col="red") +
facet_wrap(~ variables, scales = "free")
ggplot(road, aes(sample = TOT.N)) +
geom_qq(color = "black", shape = 1) + # shape = 1 gives open circles
# This line shows where the points *should* fall if the data were perfectly normal.
geom_qq_line(color = "blue", linewidth = 1)
ggplot(eda, aes(x = value, y = TOT.N)) +
# Layer 1: The scatter plot points
geom_point(alpha = 0.6) +
# Layer 2: The linear regression fit for each plot
# se = TRUE for the linear model
geom_smooth(method = "lm", se = TRUE, color = "blue", formula = 'y ~ x') +
# we add a smoother to compare against the linear plot
geom_smooth(method = "loess", se = FALSE, color = "red", formula = 'y ~ x',
span = 1.2) +
# This creates a separate plot for each of the X-variables.
facet_wrap(~ variables, scales = "free") +
# Add labels and a title
labs(
title = "Total kills (TOT.N) v Explanatory Variables",
x = "Explanatory Variables",
y = "Total Road Kill per Sector of Road"
) +
# Change the theme
theme_bw() +
theme(
strip.background = element_rect(fill = "lightblue") # Adds stip labels as the facet titles, in lightblue
)
road.glm <- glm(TOT.N ~ OPEN.L + SHRUB + WAT.RES + L.WAT.C + L.P.ROAD +
D.WAT.COUR + D.PARK,family=poisson,data=road)
summary(road.glm)
gvif_values <- performance::check_collinearity(road.glm)
print(gvif_values)
check_overdispersion(road.glm)
autoplot(road.glm, method="glm")
## plot simulated residuals
plot(road.glm, which =4)
road.glm1 <- glm(TOT.N ~ OPEN.L + SHRUB + WAT.RES + L.WAT.C + L.P.ROAD +
D.WAT.COUR + D.PARK,family=quasipoisson,data=road)
summary(road.glm1)
autoplot(road.glm1, method="glm")
road.nb <- glm.nb(TOT.N ~ OPEN.L + SHRUB + WAT.RES + L.WAT.C + L.P.ROAD +
D.WAT.COUR + D.PARK,data=road)
summary(road.nb)
autoplot(road.nb, method="glm.nb")
options(na.action=na.fail) # set options in Base R concerning missing values
summary(model.avg(dredge(road.nb), fit = TRUE, subset = TRUE))
options(na.action = "na.omit") # reset base R options
road.final <- glm.nb(TOT.N ~ D.PARK + L.WAT.C + OPEN.L, data=road)
summary(road.final)
op <- par(mfrow = c(2, 2))
plot(road.final) # no patterns....
par(op)
R <- resid(road.final, type='pearson') # extract the pearson residuals
op <- par(mfrow = c(2, 2))
plot(road$OPEN.L~R)
plot(road$L.WAT.C~R)
plot(road$D.PARK~R)
par(op)
tidy(road.final, exponentiate = TRUE)
print(r2(road.final))
# Get the log-likelihood of your full model
logLik_full <- logLik(road.final)
# To get the log-likelihood of the null model, we need to fit it first.
# The null model has only an intercept (e.g., Srich ~ 1).
model_null <- update(road.final, . ~ 1)
logLik_null <- logLik(model_null)
# Apply the formula and convert the final result to a simple number
r2_mcfadden <- as.numeric(1 - (logLik_full / logLik_null))
# Print the result - it will now be a clean number
print(r2_mcfadden)
# [1] 0.1564486
# ======================================================================
# 1. Partial Effect for Distance to Park (D.PARK)
# ======================================================================
# Create a data frame where D.PARK varies and others are held at their mean
partial_d_park <- data.frame(
D.PARK = seq(min(road$D.PARK, na.rm = TRUE),
max(road$D.PARK, na.rm = TRUE), length.out = 100),
L.WAT.C = mean(road$L.WAT.C, na.rm = TRUE),
OPEN.L = mean(road$OPEN.L, na.rm = TRUE)
)
# Predict response and confidence intervals
predictions_d_park <- predict(road.final, newdata = partial_d_park, type = "response", se.fit = TRUE)
partial_d_park$predicted <- predictions_d_park$fit
partial_d_park$lower_ci <- predictions_d_park$fit - 1.96 * predictions_d_park$se.fit
partial_d_park$upper_ci <- predictions_d_park$fit + 1.96 * predictions_d_park$se.fit
# Plot 1
p1 <- ggplot() +
# --- ADDED: Raw data points in the background ---
geom_point(data = road, aes(x = D.PARK, y = TOT.N), alpha = 0.5) +
# --- Prediction line and ribbon on top ---
geom_line(data = partial_d_park, aes(x = D.PARK, y = predicted), color = "blue", linewidth = 1) +
geom_ribbon(data = partial_d_park, aes(x = D.PARK, ymin = lower_ci, ymax = upper_ci), alpha = 0.2, fill = "blue") +
labs(title = "Partial Effect of Distance to Park",
x = "Distance to Park (D.PARK)", y = "Predicted Road Kills") +
theme_minimal()
# ======================================================================
# 2. Partial Effect for Length of Water Course (L.WAT.C)
# ======================================================================
# Create a data frame where L.WAT.C varies and others are held at their mean
partial_l_wat_c <- data.frame(
L.WAT.C = seq(min(road$L.WAT.C, na.rm = TRUE),
max(road$L.WAT.C, na.rm = TRUE), length.out = 100),
D.PARK = mean(road$D.PARK, na.rm = TRUE),
OPEN.L = mean(road$OPEN.L, na.rm = TRUE)
)
# Predict and add columns
predictions_l_wat_c <- predict(road.final, newdata = partial_l_wat_c, type = "response", se.fit = TRUE)
partial_l_wat_c$predicted <- predictions_l_wat_c$fit
partial_l_wat_c$lower_ci <- predictions_l_wat_c$fit - 1.96 * predictions_l_wat_c$se.fit
partial_l_wat_c$upper_ci <- predictions_l_wat_c$fit + 1.96 * predictions_l_wat_c$se.fit
# Plot 2
p2 <- ggplot() +
# --- ADDED: Raw data points in the background ---
geom_point(data = road, aes(x = L.WAT.C, y = TOT.N), alpha = 0.5) +
# --- Prediction line and ribbon on top ---
geom_line(data = partial_l_wat_c, aes(x = L.WAT.C, y = predicted), color = "blue", linewidth = 1) +
geom_ribbon(data = partial_l_wat_c, aes(x = L.WAT.C, ymin = lower_ci, ymax = upper_ci), alpha = 0.2, fill = "blue") +
labs(title = "Partial Effect of Water Course Length",
x = "Length of Water Course (L.WAT.C)", y = "Predicted Road Kills") +
theme_minimal()
# ======================================================================
# 3. Partial Effect for Open Land (OPEN.L)
# ======================================================================
# Create a data frame where OPEN.L varies and others are held at their mean
partial_open_l <- data.frame(
OPEN.L = seq(min(road$OPEN.L, na.rm = TRUE),
max(road$OPEN.L, na.rm = TRUE), length.out = 100),
D.PARK = mean(road$D.PARK, na.rm = TRUE),
L.WAT.C = mean(road$L.WAT.C, na.rm = TRUE)
)
# Predict and add columns
predictions_open_l <- predict(road.final, newdata = partial_open_l, type = "response", se.fit = TRUE)
partial_open_l$predicted <- predictions_open_l$fit
partial_open_l$lower_ci <- predictions_open_l$fit - 1.96 * predictions_open_l$se.fit
partial_open_l$upper_ci <- predictions_open_l$fit + 1.96 * predictions_open_l$se.fit
# Plot 3
p3 <- ggplot() +
# --- ADDED: Raw data points in the background ---
geom_point(data = road, aes(x = OPEN.L, y = TOT.N), alpha = 0.5) +
# --- Prediction line and ribbon on top ---
geom_line(data = partial_open_l, aes(x = OPEN.L, y = predicted), color = "blue", linewidth = 1) +
geom_ribbon(data = partial_open_l, aes(x = OPEN.L, ymin = lower_ci, ymax = upper_ci), alpha = 0.2, fill = "blue") +
labs(title = "Partial Effect of Open Land",
x = "Percentage of Open Land (OPEN.L)", y = "Predicted Road Kills") +
theme_minimal()
# ======================================================================
# Combine all plots into a grid
# ======================================================================
grid.arrange(p1, p2, p3, ncol = 2)
ggplot(Benthic, aes(x = NAP, y = Richness)) +
geom_point(alpha = 0.6) + # Added some transparency to the points
geom_smooth(
method = "lm",
se = TRUE, # add in some confidence interval
color = "red",       # Change line color to red
linewidth = 1.2,    # Make the line slightly thicker
formula = 'y ~ x',
) +
facet_wrap(
~ Beach
) +
# Set the y-axis viewing window to start at 0. You cannot have a negative count of species richness.
coord_cartesian(ylim = c(0, NA)) +
theme_bw()
#| label: mixed_model
#| echo: false
knitr::include_graphics("images/mixed_models_examples.png")
# List of packages
packages <- c("tidyverse", "ggfortify", "performance", "car", "skimr", "gridExtra", "broom",
"ggeffects","MASS","MuMIn", "lme4","glmmTMB", "DHARMa")
# Load all packages and install the packages we have no previously installed on the system
lapply(packages, library, character.only = TRUE)
# --- SIMULATION PARAMETERS: Define the rules for our data ---
# Use set.seed() to make our "random" data reproducible.
set.seed(42)
# Define the basic parameters for the experiment
n_groups <- 5      # Number of groups (e.g., 5 different individuals)
n_obs_per_group <- 11 # Number of observations per group (from X=0 to X=10)
x <- 0:10          # The predictor variable values
# Define the "fixed" or population-level effects (the thick black line)
pop_intercept <- 2.0  # The overall average intercept
pop_slope <- 0.5     # The overall average slope
residual_sd <- 0.8   # The random "noise" for each individual point
# Define the variance of the "random" effects
intercept_sd <- 2.0  # How much the group intercepts vary around the mean
slope_sd <- 0.8      # How much the group slopes vary (increased for more visual difference)
# --- DATA GENERATION: Create the two datasets ---
# First, generate the unique random effects for each of the 5 groups
random_intercepts <- rnorm(n_groups, mean = 0, sd = intercept_sd)
random_slopes <- rnorm(n_groups, mean = 0, sd = slope_sd)
# Generate the "Random Intercepts" dataset
data_ri <- map_df(1:n_groups, ~{
tibble(
group = as.character(.x),
x = x,
# Formula: y = (overall_intercept + group_specific_intercept) + (overall_slope * x) + error
y = (pop_intercept + random_intercepts[.x]) + (pop_slope * x) + rnorm(n_obs_per_group, 0, residual_sd),
model_type = "Random Intercepts Model"
)
})
# Generate the "Random Slopes and Intercepts" dataset
data_rs <- map_df(1:n_groups, ~{
tibble(
group = as.character(.x),
x = x,
# Formula: y = (overall_intercept + group_specific_intercept) + (overall_slope + group_specific_slope) * x + error
y = (pop_intercept + random_intercepts[.x]) + (pop_slope + random_slopes[.x]) * x + rnorm(n_obs_per_group, 0, residual_sd),
model_type = "Random Slopes + Intercepts Model"
)
})
# --- PLOTTING: Combine data and create the final figure ---
# Combine both datasets into a single data frame for plotting
full_data <- bind_rows(data_ri, data_rs)
# Create a small data frame to hold the annotation text and arrow coordinates
annotations <- tibble(
model_type = c("Random Intercepts Model", "Random Slopes + Intercepts Model"),
label = c("Groups differ\nin baseline (intercept)", "Groups differ in\nboth baseline & slope"),
x_arrow = c(0, 7),
y_arrow = c(10.5, 10.5),
x_text = c(0.5, 3),
y_text = c(11, 11),
x_arrow_end = c(0, 7),
y_arrow_end = c(5, 5)
)
# Create the final plot using ggplot2
ggplot(full_data, aes(x = x, y = y, color = group, group = group)) +
# Add the individual group lines (dashed and now fully opaque with alpha=1)
geom_line(linetype = "dashed", alpha = 1) +
# Add the individual data points (also fully opaque)
geom_point(alpha = 1) +
# Add the overall "fixed effect" or population-level line
geom_abline(intercept = pop_intercept, slope = pop_slope,
color = "black", linewidth = 1.5) +
# Add the arrows using the annotations data frame
geom_segment(
data = annotations,
aes(x = x_arrow, y = y_arrow, xend = x_arrow_end, yend = y_arrow_end),
arrow = arrow(length = unit(0.3, "cm")),
inherit.aes = FALSE # This prevents ggplot from trying to color the arrows
) +
# Add the text labels using the annotations data frame
geom_text(
data = annotations,
aes(x = x_text, y = y_text, label = label),
hjust = 0, vjust = 0,
inherit.aes = FALSE
) +
# Use facet_wrap to create the two side-by-side plots
facet_wrap(~ model_type) +
# --- Final aesthetic touches ---
scale_color_brewer(palette = "Set2") +
theme_bw() +
labs(x = "Predictor (X)", y = "Response (Y)") +
theme(
legend.position = "none", # Hide the legend as it's redundant
panel.grid.minor = element_blank(),
panel.grid.major = element_line(linetype = "dashed", color = "grey85"),
strip.background = element_blank(), # Remove facet title background
strip.text = element_text(face = "bold", size = 14), # Style facet titles
axis.title = element_text(size = 12)
)
Benthic <- read_csv("~/Documents/GitHub/Teaching/LM_25556Environmental_Analysis/Data/RIKZ.csv")
ggplot(Benthic, aes(x = NAP, y = Richness)) +
geom_point(alpha = 0.6) + # Added some transparency to the points
geom_smooth(
method = "lm",
se = TRUE, # add in some confidence interval
color = "red",       # Change line color to red
linewidth = 1.2,    # Make the line slightly thicker
formula = 'y ~ x',
) +
facet_wrap(
~ Beach
) +
# Set the y-axis viewing window to start at 0. You cannot have a negative count of species richness.
coord_cartesian(ylim = c(0, NA)) +
theme_bw()
# We could try to add a covariate in for beach as a form of ANCOVA
M1 <- lm(Richness ~ NAP * as.factor(Beach), data = Benthic)
summary(M1)
# Plot residual - it hasn't improved that either!
op <- par(mfrow = c(2,2))
plot(beach.lm1)
ggplot(Benthic, aes(x = NAP, y = Richness)) +
geom_point(alpha = 0.6) + # Added some transparency to the points
geom_smooth(
method = "lm",
se = TRUE, # add in some confidence interval
color = "red",       # Change line color to red
linewidth = 1.2,    # Make the line slightly thicker
formula = 'y ~ x',
) +
facet_wrap(
~ Beach
) +
# Set the y-axis viewing window to start at 0. You cannot have a negative count of species richness.
coord_cartesian(ylim = c(0, NA)) +
theme_bw()
ggplot(Benthic, aes(x = NAP, y = Richness)) +
geom_point(alpha = 0.6) + # Added some transparency to the points
geom_smooth(
method = "lm",
se = TRUE, # add in some confidence interval
color = "red",       # Change line color to red
linewidth = 1.2,    # Make the line slightly thicker
formula = 'y ~ x',
) +
facet_wrap(
~ Beach
) +
# Set the y-axis viewing window to start at 0. You cannot have a negative count of species richness.
coord_cartesian(ylim = c(0, NA)) +
theme_bw()
# Plot residual - it hasn't improved that either!
op <- par(mfrow = c(2,2))
plot(M1)
par(op)
# not much better..
# We are using lme4 here
M1 <- glmer(Richness ~ NAP * fExp + (1 | beach),
data = beach, family = "poisson")	# Random slope model
# We are using lme4 here
M1 <- glmer(Richness ~ NAP * Exp + (1 | beach),
data = beach, family = "poisson")	# Random slope model
# We are using lme4 here
M1 <- glmer(Richness ~ NAP * Exp + (1 | beach),
data = Benthic, family = "poisson")	# Random slope model
View(Benthic)
# We are using lme4 here
M1 <- glmer(Richness ~ NAP * Exposure + (1 | beach),
data = Benthic, family = "poisson")	# Random slope model
# We are using lme4 here
M1 <- glmer(Richness ~ NAP * Exposure + (1 | as.factor(Beach)),
data = Benthic, family = "poisson")	# Random slope model
# We are using lme4 here
M1 <- glmer(Richness ~ NAP * Exposure + (1 | Beach),
data = Benthic, family = "poisson")	# Random slope model
# There might be an error message - it's okay!
M2 <- glmer(Richness ~1 + NAP * Exposure + (NAP | Beach),
data = Benthic, family = "poisson") # Random intercept and slope
# Compare models
AIC(M1,M2)
# The Anova test confirms the difference is significant
anova(M1, M2, test = "Chisq")
# Now determine the best fixed structure. We tell MuMin that the we used REML.
# Library
#options(na.action=na.fail) # set options in Base R concerning missing values
#summary(model.avg(dredge(M7), fit = TRUE, subset = TRUE), method = "REML")
#options(na.action = "na.omit") # reset base R options
over_dispersion(M1)
dispersion(M1)
??performance:overdispersion
check_overdispersion(M1)
# We are using lme4 here
M1 <- glmer(Richness ~ NAP * Exposure + (1 | Beach),
data = Benthic, family = "poisson")	# Random slope model
# There might be an error message - it's okay!
M2 <- glmer(Richness ~ NAP * Exposure + (NAP | Beach),
data = Benthic, family = "poisson") # Random intercept and slope
# Compare models
AIC(M1,M2)
# The Anova test confirms the difference is significant
anova(M1, M2, test = "Chisq")
# Now determine the best fixed structure. We tell MuMin that the we used REML.
# Library
#options(na.action=na.fail) # set options in Base R concerning missing values
#summary(model.avg(dredge(M7), fit = TRUE, subset = TRUE), method = "REML")
#options(na.action = "na.omit") # reset base R options
class(Benthic)
